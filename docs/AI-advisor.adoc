= Local AI Component
:icons: unicode

== Purpose

A local AI module may be included to assist in interpreting multi-sensor anomalies.  
It does not replace deterministic logic. It provides explanatory context and pattern recognition over time.

== Role in System

* Input: structured telemetry from sensors (binary states, confidence, persistence).
* Output: classification of anomaly type, brief explanation, and uncertainty estimate.
* Scope: advisory only. The system must operate correctly without it.

== Data Flow

1. Sensors produce periodic JSON records.
2. Core logic applies deterministic rules and scores.
3. AI module optionally receives the last N records (sliding window).
4. Model returns interpretation text and a label.
5. Output is appended to logs and UI.

== Model Requirements

Local execution, bounded resources, predictable behavior.  
Small transformer or tree-based model acceptable.  
Training starts from synthetic patterns and iterates on collected logs.

== Behavior

The AI correlates signals across time and domains to reduce false positives and highlight plausible causes (local outage, regional infrastructure issue, RF environment anomaly, or sensor fault).

It is not allowed to control sensors or trigger emergency actions.

== Failure Handling

If the AI component is unavailable or produces invalid output, the system continues using deterministic logic only. Logs record the absence.

== Security

Offline inference only.  
No external network calls.  
Sandboxed execution.

== Architecture and Software Stack

Each Pi node continuously streams network and environmental telemetry (latency, DNS/BGP status, sensor data) to the central AI node.  
The AI node processes the incoming streams using local inference models and feeds summarized results back into the Doomsday monitoring framework.
It runs a lightweight inference server based on **LLaMA-compatible architectures**, deployed via `llama.cpp` or `text-generation-webui` with quantized models (3B–7B).  
This environment supports:

* **Temporal correlation analysis** between network anomalies and physical sensor events.  
* **Context-aware classification** of incident types.  
* **Generation of natural-language diagnostic summaries** for human review or logging.

The operating system is typically a **Linux workstation** or **mini PC** running a dedicated container (e.g., Docker or Podman) for model execution and data ingestion.

== Hardware Requirements

Typical reference setup:

* CPU: x86_64, 8 cores or higher  
* RAM: 32 GB minimum (recommended 64 GB)  
* Storage: 512 GB SSD  
* GPU (optional): NVIDIA GTX/RTX with 6 GB+ VRAM, or integrated inference via CPU quantization  

This node acts as the **intelligent hub** of the Doomsday network, capable of performing real-time reasoning and model updates while remaining fully autonomous from cloud services.

== Integration Purpose

The dedicated AI node allows the system to perform:

* **Cross-node event correlation** — identifying patterns among geographically distributed sentinels.  
* **Anomaly classification and ranking** — distinguishing routine instability from exceptional events.  
* **Predictive modeling** — inferring potential large-scale outages before full propagation.  

By isolating AI computation on a powerful but local PC, Doomsday maintains its distributed, low-power sensor architecture while gaining advanced analytical capability.  
The result is a hybrid system — lightweight at the edge, intelligent at the core — capable of understanding not only that the network is failing, but also *why*. This module is an optional analytical layer. Its value is improved interpretation and operator clarity. Core sensing, scoring, and alert logic remain fully rule-based and independent.
